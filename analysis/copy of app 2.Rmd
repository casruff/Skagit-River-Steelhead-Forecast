---
title: R2. Model fitting and evaluation 
subtitle: 2020 - 2021 Skagit River steelhead forecast.
output:
  pdf_document:
    toc: yes
    toc_depth: '3'
  html_document:
    fig_caption: yes
    theme: cerulean
    toc: yes
    toc_depth: 3
    toc_float: yes
---

***

This is version `r paste0('0.',format(Sys.time(), '%y.%m.%d'))`.

***

```{r set_options, echo = FALSE, message = FALSE}
options(width = 100)
knitr::opts_chunk$set(message = FALSE)
set.seed(123)
if(file.exists("cnt_time.txt")) {
  file.remove("cnt_time.txt")
}

mod_names <- data.frame(mod = rep(c("Beverton-Holt", "Beverton-Holt"), 1),
                        error = rep(c("MA1 & AR1", "AR1"), 1))
```

# Requirements
All analyses require the [R software](https://cran.r-project.org/) (v3.4.3) for data retrieval, data processing, and summarizing model results, and the [JAGS software](http://mcmc-jags.sourceforge.net/) (v4.2.0) for Markov chain Monte Carlo (MCMC) simulation. Please note that some of the R code below may not work with older versions of JAGS due to some changes in the ways that arrays are handled.

We also need a few packages that are not included with the base installation of R, so we begin by installing them (if necessary) and then loading them.

```{r load_pkgs, message = FALSE, warning = FALSE}
if(!require("here")) {
  install.packages("here")
  library("here")
}
if(!require("readr")) {
  install.packages("readr")
  library("readr")
}
if(!require("rjags")) {
  install.packages("rjags")
  library("rjags")
}
if(!require("loo")) {
  install.packages("loo")
  library("loo")
}
if(!require("ggplot2")) {
  install.packages("ggplot2")
  library("ggplot2")
}
if(!require("coda")) {
  install.packages("coda")
  library("coda")
}
if(!require("shinystan")) {
  install.packages("shinystan")
  library("shinystan")
}
if(!require("R2jags")) {
  install.packages("R2jags")
  library("R2jags")
}
if(!require("dclone")) {
  install.packages("dclone")
  library("dclone")
}
if(!require("snow")) {
  install.packages("snow")
  library("snow")
}
## set directory locations
datadir <- here("data")
jagsdir <- here("jags")
analdir <- here("analysis")
savedir <- here("analysis/cache")
```

We also need a couple of helper functions.

```{r define_funcs}
## better round
Re2prec <- function(x, map = "round", prec = 1) {
  ## 'map' can be "round", "floor", or "ceiling"
  ## 'prec' is nearest value (eg, 0.1 means to nearest tenth; 1 gives normal behavior)
  if(prec<=0) { stop("\"prec\" cannot be less than or equal to 0") }
  do.call(map,list(x/prec))*prec
}

## wrapper function to fit JAGS models & rearrange output
fit_jags <- function(model, data, params, inits, ctrl, dir = jagsdir) {
  jm <- jags.model(file.path(jagsdir, model),
                   data,
                   inits,
                   ctrl$chains,
                   ctrl$burn,
                   quiet = TRUE)
  return(coda.samples(jm, params, ctrl$length, ctrl$thin))
}

#alternative wrapper to fit model in parallel; one chain per core
fit_jags2<-function(model,data,params,inits,ctrl,dir=jagsdir){
  # jm<-jags.parallel(data=data, 
  #                   inits=inits,
  #                   parameters.to.save=params,
  #                   model.file = file.path(jagsdir, model),
  #                   n.chains = ctrl$chains, 
  #                   n.iter = ctrl$length, 
  #                   n.burnin = ctrl$burn,
  #                   n.thin = ctrl$thin,
  #                   DIC = TRUE,
  # )
  # write.csv(jm$BUGSoutput$summary,file.path(savedir,paste(model,".csv",sep="")))
  # jm<-jags.parfit(data=data,
  #                   inits=inits,
  #                   parameters.to.save=params,
  #                   model.file = file.path(jagsdir, model),
  #                   n.chains = ctrl$chains,
  #                   n.iter = ctrl$length,
  #                   n.burnin = ctrl$burn,
  #                   n.thin = ctrl$thin,
  #                   DIC = TRUE,
  # )
  # return(as.mcmc.list(as.mcmc(jm)))
  cl <- makeCluster(3, type = "SOCK")
  inits2 <- jags.fit(data=data,
                     params=params, 
                     model=file.path(jagsdir, model), 
                     inits=inits,
                     n.chains=ctrl$chains,
                     n.adapt = 0,
                     n.update = 0,
                     n.iter = 0)$state(internal = TRUE)
  jm <- jags.parfit(cl=cl,
                    data = data,
                    params = params, 
                    model = file.path(jagsdir, model),
                    inits = inits2,
                    n.adapt = ctrl$burn*0.5,
                    n.update = ctrl$burn*0.5,
                    n.iter = ctrl$length-ctrl$burn,
                    thin = ctrl$thin,
                    n.chains = ctrl$chains
                    )
  stopCluster(cl)
  return(jm)
}

```

# User inputs
We begin by supplying values for the following parameters, which we need for model fitting and evaluation.

```{r get_user_inputs}
## first & last years of fish data
yr_frst <- 1978
yr_last <- 2020

## min & max adult age classes
age_min <- 3
age_max <- 8
## years (if any) of age-comp to skip; see below
age_skip <- 0

## number of years ahead for run forecasts
n_fore <- 1

## number of recent year forecasts
n_forecasts <- 5

## upper threshold for Gelman & Rubin's potential scale reduction factor (Rhat).
Rhat_thresh <- 1.1
```

Next we specify the names of three necessary data files containing the following information:
 
 1. observed total number of adult spawners (escapement) by year;
 2. observed age composition of adult spawners by year;
 3. observed total harvest by year;

```{r get_filenames}
## 1. file with escapement data
## [n_yrs x 2] matrix of obs counts; 1st col is calendar yr
fn_esc <- "skagit_sthd_esc.csv"

## 2. file with age comp data
## [n_yrs x (1+A)]; 1st col is calendar yr
fn_age <- "skagit_sthd_age.csv"

## 3. file with harvest data
## [n_yrs x 2] matrix of obs catch; 1st col is calendar yr
fn_harv <- "skagit_sthd_catch.csv"
```

# Loading the fish data
Here we load in the first three data files and do some simple calculations and manipulations. First the spawner data:

```{r get_escapement_data}
## escapement
dat_esc <- read_csv(file.path(datadir, fn_esc))
## years of data
dat_yrs <- dat_esc$year

## number of years of data
n_yrs <- length(dat_yrs)

## log of escapement
ln_dat_esc <- c(log(dat_esc$escapement),rep(NA,n_fore))
```

Next the age composition data:

```{r get_age_data}
## age comp data
dat_age <- read_csv(file.path(datadir, fn_age))
## num of age classes
A <- age_max - age_min + 1
## drop year col & first age_min+age_skip rows
dat_age <- dat_age[-(1:(age_min+age_skip)),-1]
      
## add row(s) of NA's for forecast years
if(n_fore > 0) {
  dat_age <- rbind(dat_age,
                   matrix(0, n_fore, A,
                          dimnames =list(n_yrs+seq(n_fore),
                                         colnames(dat_age))))
}
## total num of age obs by cal yr
dat_age[,"sum"] <- apply(dat_age, 1, sum)
## row indices for any years with no obs age comp
idx_NA_yrs <- which(dat_age$sum<A, TRUE)
## replace 0's in yrs w/o any obs with NA's
dat_age[idx_NA_yrs,(1:A)] <- NA
## change total in yrs w/o any obs from 0 to A to help dmulti()
dat_age[idx_NA_yrs,"sum"] <- A
## convert class
dat_age <- as.matrix(dat_age)
```

And then the harvest data:

```{r get_harvest}
## harvest
dat_harv <- read_csv(file.path(datadir, fn_harv))
## drop year col & first age_max rows
dat_harv <- c(dat_harv$catch,rep(NA,n_fore))
```

# Loading the covariates

Our analysis investigates 5 covariates as possible drivers of the population's instrinic growth rate:

1. Maximum river discharge in winter;
2. Minimum river discharge in summer;
3. North Pacific Gyre Oscillation;

All of the covariates are contained in the file `/data/skagit_sthd_covars.csv`. We will load and then standardize them to have zero-mean and unit-variance.

```{r get_covariates}
dat_cvrs <- read_csv(file.path(datadir, "skagit_sthd_covars.csv"))
## drop year col
dat_cvrs <- dat_cvrs[,-1] 
## transform the covariates to z-scores
scl_cvrs <- as.matrix(scale(dat_cvrs))
## total number of covariates
n_cov <- dim(dat_cvrs)[2] 
```

# Specifying models in JAGS

Now we can specify the  model in JAGS. We fit a total one model, which we outline below, based on a beverton holt process model with covariates.


## Beverton-Holt with covars 

```{r JAGS_BH_cov2_AR}
cat("
    model {
    
    ##--------
    ## PRIORS
    ##--------
    ## alpha = intrinsic productivity
    alpha ~ dnorm(0,0.001) T(0,);
    mu_BH_a <- log(alpha);
    E_BH_a <- mu_BH_a + sigma_r/(2 - 2*phi^2);
    
    ## strength of dens depend
    beta_inv ~ dnorm(0, 1e-9) T(0,);
    beta <- 1/beta_inv;
    
    ## covariate effects
    for(i in 1:n_cov) { gamma[i] ~ dnorm(0,0.01) }
    
    ## AR(1) coef for proc errors
    #phi ~ dunif(-0.999,0.999);
    #phi <- 0;
    phi_prior ~ dbeta(2,2);
    phi <- phi_prior*2-1;
    #phi ~ dunif(0,0.999);
    
    ## innovation in first year
    innov_1 ~ dnorm(0,tau_r*(1-phi*phi));
    
    ## process variance for recruits model
    sigma_r ~ dnorm(0, 2e-2) T(0,);
    tau_r <- 1/sigma_r;
    
    ## obs variance for spawners
    tau_s <- 1/sigma_s;
    sigma_s ~ dnorm(0, 0.001) T(0,);
    
    ## unprojectable early recruits;
    ## hyper mean across all popns
    Rec_mu ~ dnorm(0,0.001);
    ## hyper SD across all popns
    Rec_sig ~ dunif(0,100);
    ## precision across all popns
    Rec_tau <- pow(Rec_sig,-2);
    ## multipliers for unobservable total runs
    ttl_run_mu ~ dunif(1,5);
    ttl_run_tau ~ dunif(1,20);
    
    ## get total cal yr returns for first age_min yrs
    for(i in 1:(age_min+age_skip)) {
    ln_tot_Run[i] ~ dnorm(ttl_run_mu*Rec_mu,Rec_tau/ttl_run_tau);
    tot_Run[i] <- exp(ln_tot_Run[i]);
    }
    
    ## maturity schedule
    ## unif vec for Dirch prior
    theta <- c(1,10,10,5,1,1)
    ## hyper-mean for maturity
    pi_eta ~ ddirch(theta);
    ## hyper-prec for maturity
    pi_tau ~ dnorm(0, 0.01) T(0,);
    for(t in 1:(n_yrs-age_min+n_fore)) { pi_vec[t,1:A] ~ ddirch(pi_eta*pi_tau) }
    
    ## estimated harvest rate
    for(t in 1:(n_yrs+n_fore)) { h_rate[t] ~ dunif(0,1) }
    ##------------
    ## LIKELIHOOD
    ##------------
    ## predicted recruits in BY t
    covar[1] <- inprod(gamma,mod_cvrs[1,]);
    ln_BH_a[1] <- mu_BH_a + covar[1];
    E_ln_Rec[1] <- ln_BH_a[1] + ln_Sp[1] - log(1 + beta*Sp[1]) + phi*innov_1;
    tot_ln_Rec[1] ~ dnorm(E_ln_Rec[1],tau_r);
    res_ln_Rec[1] <- tot_ln_Rec[1] - E_ln_Rec[1];
    w[1] <- phi * innov_1 + res_ln_Rec[1];
    ## median of total recruits
    tot_Rec[1] <- exp(tot_ln_Rec[1]);
    
    ## R/S
    ln_RS[1] <- tot_ln_Rec[1] - ln_Sp[1];
    
    ## brood-yr recruits by age
    for(a in 1:A) {
    Rec[1,a] <- tot_Rec[1] * pi_vec[1,a];
    }
    
    ## brood years 2:(n_yrs-age_min)
    for(t in 2:(n_yrs-age_min+n_fore)) {
    ## predicted recruits in BY t
    covar[t] <- inprod(gamma, mod_cvrs[t,]);
    ln_BH_a[t] <- mu_BH_a + covar[t];
    E_ln_Rec[t] <- ln_BH_a[t] + ln_Sp[t] - log(1 + beta*Sp[t]) + phi*res_ln_Rec[t-1];
    tot_ln_Rec[t] ~ dnorm(E_ln_Rec[t],tau_r);
    res_ln_Rec[t] <- tot_ln_Rec[t] - E_ln_Rec[t];
    w[t] <- phi * res_ln_Rec[t-1] + res_ln_Rec[t];
    
    ## median of total recruits
    tot_Rec[t] <- exp(tot_ln_Rec[t]);
    
    ## R/S
    ln_RS[t] <- tot_ln_Rec[t] - ln_Sp[t];
    
    ## brood-yr recruits by age
    for(a in 1:A) {
    Rec[t,a] <- tot_Rec[t] * pi_vec[t,a];
    }
    } ## end t loop over year
    
    ## get predicted calendar year returns by age
    ## matrix Run has dim [(n_yrs-age_min) x A]
    ## step 1: incomplete early broods
    ## first cal yr of this grp is first brood yr + age_min + age_skip
    
    for(i in 1:(age_max-age_min-age_skip)) {
    ## projected recruits
    for(a in 1:(i+age_skip)) {
    Run[i,a] <- Rec[(age_skip+i)-a+1,a];
    }
    
    ## imputed recruits
    for(a in (i+1+age_skip):A) {
    lnRec[i,a] ~ dnorm(Rec_mu,Rec_tau);
    Run[i,a] <- exp(lnRec[i,a]);
    }
    
    ## total run size
    tot_Run[i+age_min+age_skip] <- sum(Run[i,1:A]);
    
    ## predicted age-prop vec for multinom
    for(a in 1:A) {
    age_v[i,a] <- Run[i,a] / tot_Run[i+age_min];
    }
    
    ## multinomial for age comp
    dat_age[i,1:A] ~ dmulti(age_v[i,1:A],dat_age[i,A+1]);
    lp_age[i] <- logdensity.multi(dat_age[i,1:A],age_v[i,1:A],dat_age[i,A+1]);
    }
    
    ## step 2: info from complete broods
    ## first cal yr of this grp is first brood yr + age_max
    for(i in (A-age_skip):(n_yrs-age_min-age_skip+n_fore)) {
    for(a in 1:A) {
    Run[i,a] <- Rec[(age_skip+i)-a+1,a];
    }
    
    ## total run size
    tot_Run[i+age_min+age_skip] <- sum(Run[i,1:A]);
    
    ## predicted age-prop vec for multinom
    for(a in 1:A) {
    age_v[i,a] <- Run[i,a] / tot_Run[i+age_min];
    }
    
    ## multinomial for age comp
    dat_age[i,1:A] ~ dmulti(age_v[i,1:A],dat_age[i,A+1]);
    lp_age[i] <- ifelse(i < n_yrs-age_min-age_skip+n_fore, logdensity.multi(dat_age[i,1:A],age_v[i,1:A],dat_age[i,A+1]),0);
    }
    
    ## get predicted calendar year spawners
    ## first cal yr is first brood yr
    for(t in 1:(n_yrs+n_fore)) {
    ## obs model for spawners
    #Sp[t] <- max(10,tot_Run[t] - dat_harv[t]);
    est_harv[t] = ifelse(t > n_yrs,1,h_rate[t] * tot_Run[t]);
    
    dat_harv[t] ~ dlnorm(log(est_harv[t]), 20);
    Sp[t] = tot_Run[t] - est_harv[t];
    ln_Sp[t] <- log(Sp[t]);
    ln_dat_esc[t] ~ dnorm(ln_Sp[t], tau_s);
    
    lp_esc[t] <- ifelse(t < n_yrs + 1,logdensity.norm(ln_dat_esc[t],ln_Sp[t], tau_s),0);
    }
  } ## end model description
    
  ", file=file.path(jagsdir, "IPM_BH_cov_AR.txt"))

```

## Beverton-Holt with covars 

```{r JAGS_BH_cov2_MA1_AR1}
cat("
model {
  
  ##--------
  ## PRIORS
  ##--------
  ## alpha = intrinsic productivity
  alpha ~ dnorm(0,0.001) T(0,);
  mu_BH_a <- log(alpha);
  E_BH_a <- mu_BH_a + sigma_r/(2 - 2*phi^2);
  
  ## strength of dens depend
  beta_inv ~ dnorm(0, 1e-9) T(0,);
  beta <- 1/beta_inv;
  
  ## covariate effects
  for(i in 1:n_cov) { gamma[i] ~ dnorm(0,0.01) }

  ## AR(1) coef for recruitment residual
  #phi ~ dunif(-0.999,0.999);
  #phi <- 0;
  phi_prior ~ dbeta(2,2);
  phi <- phi_prior*2-1;
  #phi ~ dunif(0,0.999);

  ## MA(1) coef recruitment residual
  theta_res_prior ~ dbeta(2,2);
  theta_res <- theta_res_prior*2-1;
  #theta_res ~ dunif(0,0.999);

  ## innovation in first year
  #innov_1 ~ dnorm(0,tau_r*(1-phi*phi));#AR1
  innov_1 ~ dnorm(0,(1-phi^2)/((1+2*phi*theta_res+theta_res^2)*sigma_r^2));#AR1MA1
  
  ## process variance for recruits model
  sigma_r ~ dnorm(0, 2e-2) T(0,);
  tau_r <- 1/sigma_r;
  
  ## obs variance for spawners
  tau_s <- 1/sigma_s;
  sigma_s ~ dnorm(0, 0.001) T(0,);
  
  ## unprojectable early recruits;
  ## hyper mean across all popns
  Rec_mu ~ dnorm(0,0.001);
  ## hyper SD across all popns
  Rec_sig ~ dunif(0,100);
  ## precision across all popns
  Rec_tau <- pow(Rec_sig,-2);
  ## multipliers for unobservable total runs
	ttl_run_mu ~ dunif(1,5);
	ttl_run_tau ~ dunif(1,20);

  ## get total cal yr returns for first age_min yrs
  for(i in 1:(age_min+age_skip)) {
		ln_tot_Run[i] ~ dnorm(ttl_run_mu*Rec_mu,Rec_tau/ttl_run_tau);
		tot_Run[i] <- exp(ln_tot_Run[i]);
  }
  
  ## maturity schedule
  ## unif vec for Dirch prior
  theta <- c(1,10,10,5,1,1)
  ## hyper-mean for maturity
  pi_eta ~ ddirch(theta);
  ## hyper-prec for maturity
  pi_tau ~ dnorm(0, 0.01) T(0,);
  for(t in 1:(n_yrs-age_min+n_fore)) { pi_vec[t,1:A] ~ ddirch(pi_eta*pi_tau) }
  
  ## estimated harvest rate
  for(t in 1:(n_yrs+n_fore)) { h_rate[t] ~ dunif(0,1) }

  ##------------
  ## LIKELIHOOD
  ##------------
  ## predicted recruits in BY t
  covar[1] <- inprod(gamma,mod_cvrs[1,]);
  ln_BH_a[1] <- mu_BH_a + covar[1];
  E_ln_Rec[1] <- ln_BH_a[1] + ln_Sp[1] - log(1 + beta*Sp[1]) + phi * innov_1 + theta_res * 0;
  tot_ln_Rec[1] ~ dnorm(E_ln_Rec[1], tau_r);
  res_ln_Rec[1] <- tot_ln_Rec[1] - E_ln_Rec[1];
  w[1] <- phi * innov_1 + theta_res * 0 + res_ln_Rec[1] 
    
  ## median of total recruits
  tot_Rec[1] <- exp(tot_ln_Rec[1]);
  
  ## R/S
  ln_RS[1] <- tot_ln_Rec[1] - ln_Sp[1];
  
  ## brood-yr recruits by age
  for(a in 1:A) {
    Rec[1,a] <- tot_Rec[1] * pi_vec[1,a];
  }
  
  ## brood years 2:(n_yrs-age_min)
  for(t in 2:(n_yrs-age_min+n_fore)) {
    ## predicted recruits in BY t
    covar[t] <- inprod(gamma, mod_cvrs[t,]);
    ln_BH_a[t] <- mu_BH_a + covar[t]; 
    
    #=============================================
    #version 4; more similar to AR1 original model
    #=============================================
    E_ln_Rec[t] <- ln_BH_a[t] + ln_Sp[t] - log(1 + beta*Sp[t]) + phi * w[t-1] + theta_res * res_ln_Rec[t-1];
    tot_ln_Rec[t] ~ dnorm(E_ln_Rec[t], tau_r);
    res_ln_Rec[t] <- tot_ln_Rec[t] - E_ln_Rec[t];
    w[t] <- phi * w[t-1] + theta_res * res_ln_Rec[t-1] + res_ln_Rec[t]; 
    
    
    ## median of total recruits
    tot_Rec[t] <- exp(tot_ln_Rec[t]);
    ## R/S
    ln_RS[t] <- tot_ln_Rec[t] - ln_Sp[t];
    ## brood-yr recruits by age
    for(a in 1:A) {
      Rec[t,a] <- tot_Rec[t] * pi_vec[t,a];
    }
  } ## end t loop over year
  
  ## get predicted calendar year returns by age
  ## matrix Run has dim [(n_yrs-age_min) x A]
  ## step 1: incomplete early broods
  ## first cal yr of this grp is first brood yr + age_min + age_skip
  for(i in 1:(age_max-age_min-age_skip)) {
    ## projected recruits
    for(a in 1:(i+age_skip)) {
      Run[i,a] <- Rec[(age_skip+i)-a+1,a];
    }
    ## imputed recruits
    for(a in (i+1+age_skip):A) {
      lnRec[i,a] ~ dnorm(Rec_mu,Rec_tau);
      Run[i,a] <- exp(lnRec[i,a]);
    }
    ## total run size
    tot_Run[i+age_min+age_skip] <- sum(Run[i,1:A]);
    ## predicted age-prop vec for multinom
    for(a in 1:A) {
      age_v[i,a] <- Run[i,a] / tot_Run[i+age_min];
    }
    ## multinomial for age comp
    dat_age[i,1:A] ~ dmulti(age_v[i,1:A],dat_age[i,A+1]);
    lp_age[i] <- logdensity.multi(dat_age[i,1:A],age_v[i,1:A],dat_age[i,A+1]);
  }
  
  ## step 2: info from complete broods
  ## first cal yr of this grp is first brood yr + age_max
  for(i in (A-age_skip):(n_yrs-age_min-age_skip+n_fore)) {
    for(a in 1:A) {
      Run[i,a] <- Rec[(age_skip+i)-a+1,a];
    }
    ## total run size
    tot_Run[i+age_min+age_skip] <- sum(Run[i,1:A]);
    ## predicted age-prop vec for multinom
    for(a in 1:A) {
      age_v[i,a] <- Run[i,a] / tot_Run[i+age_min];
    }
    ## multinomial for age comp
    dat_age[i,1:A] ~ dmulti(age_v[i,1:A],dat_age[i,A+1]);
    #lp_age[i] <- logdensity.multi(dat_age[i,1:A],age_v[i,1:A],dat_age[i,A+1]);
    lp_age[i] <- ifelse(i < n_yrs-age_min-age_skip+n_fore,
    logdensity.multi(dat_age[i,1:A],age_v[i,1:A],dat_age[i,A+1]),0)
  }
  
  ## get predicted calendar year spawners
  ## first cal yr is first brood yr
  for(t in 1:(n_yrs+n_fore)) {
    ## obs model for spawners
    # Sp[t] <- max(10,tot_Run[t] - dat_harv[t]);
    est_harv[t] = h_rate[t] * tot_Run[t];
    dat_harv[t] ~ dlnorm(log(est_harv[t]), 20);
    Sp[t] = tot_Run[t] - est_harv[t];
    ln_Sp[t] <- log(Sp[t]);
    ln_dat_esc[t] ~ dnorm(ln_Sp[t], tau_s);
    lp_esc[t] <- ifelse(t < n_yrs + 1,logdensity.norm(ln_dat_esc[t],ln_Sp[t], tau_s),0);
  }
  
} ## end model description
    
  ", file=file.path(jagsdir, "IPM_BH_cov_MA1_AR1.txt"))

```
## Beverton-Holt with covars 

```{r JAGS_BH_cov2_AR1_resid}
cat("
model {
  
  ##--------
  ## PRIORS
  ##--------
  ## alpha = intrinsic productivity
  alpha ~ dnorm(0,0.001) T(0,);
  mu_BH_a <- log(alpha);
  E_BH_a <- mu_BH_a + sigma_r/(2 - 2*phi^2);
  
  ## strength of dens depend
  beta_inv ~ dnorm(0, 1e-9) T(0,);
  beta <- 1/beta_inv;
  
  ## covariate effects
  for(i in 1:n_cov) { gamma[i] ~ dnorm(0,0.01) }

  ## AR(1) coef for recruitment residual
  #phi ~ dunif(-0.999,0.999);
  #phi <- 0;
  phi_prior ~ dbeta(2,2);
  phi <- phi_prior*2-1;
  #phi ~ dunif(0,0.999);

  ## innovation in first year
  innov_1 ~ dnorm(0,tau_r*(1-phi*phi));#AR1

  ## process variance for recruits model
  sigma_r ~ dnorm(0, 2e-2) T(0,);
  tau_r <- 1/sigma_r;
  
  ## obs variance for spawners
  tau_s <- 1/sigma_s;
  sigma_s ~ dnorm(0, 0.001) T(0,);
  
  ## unprojectable early recruits;
  ## hyper mean across all popns
  Rec_mu ~ dnorm(0,0.001);
  ## hyper SD across all popns
  Rec_sig ~ dunif(0,100);
  ## precision across all popns
  Rec_tau <- pow(Rec_sig,-2);
  ## multipliers for unobservable total runs
	ttl_run_mu ~ dunif(1,5);
	ttl_run_tau ~ dunif(1,20);

  ## get total cal yr returns for first age_min yrs
  for(i in 1:(age_min+age_skip)) {
		ln_tot_Run[i] ~ dnorm(ttl_run_mu*Rec_mu,Rec_tau/ttl_run_tau);
		tot_Run[i] <- exp(ln_tot_Run[i]);
  }
  
  ## maturity schedule
  ## unif vec for Dirch prior
  theta <- c(1,10,10,5,1,1)
  ## hyper-mean for maturity
  pi_eta ~ ddirch(theta);
  ## hyper-prec for maturity
  pi_tau ~ dnorm(0, 0.01) T(0,);
  for(t in 1:(n_yrs-age_min+n_fore)) { pi_vec[t,1:A] ~ ddirch(pi_eta*pi_tau) }
  
  ## estimated harvest rate
  for(t in 1:(n_yrs+n_fore)) { h_rate[t] ~ dunif(0,1) }

  ##------------
  ## LIKELIHOOD
  ##------------
  ## predicted recruits in BY t
  covar[1] <- inprod(gamma,mod_cvrs[1,]);
  ln_BH_a[1] <- mu_BH_a + covar[1];
  E_ln_Rec[1] <- ln_BH_a[1] + ln_Sp[1] - log(1 + beta*Sp[1]) + phi * innov_1;
  tot_ln_Rec[1] ~ dnorm(E_ln_Rec[1], tau_r);
  res_ln_Rec[1] <- tot_ln_Rec[1] - E_ln_Rec[1];
  w[1] <- phi * innov_1 + res_ln_Rec[1];
  
  ## median of total recruits
  tot_Rec[1] <- exp(tot_ln_Rec[1]);
  
  ## R/S
  ln_RS[1] <- tot_ln_Rec[1] - ln_Sp[1];
  
  ## brood-yr recruits by age
  for(a in 1:A) {
    Rec[1,a] <- tot_Rec[1] * pi_vec[1,a];
  }
  
  ## brood years 2:(n_yrs-age_min)
  for(t in 2:(n_yrs-age_min+n_fore)) {
    ## predicted recruits in BY t
    covar[t] <- inprod(gamma, mod_cvrs[t,]);
    ln_BH_a[t] <- mu_BH_a + covar[t]; 
    E_ln_Rec[t] <- ln_BH_a[t] + ln_Sp[t] - log(1 + beta*Sp[t]) + phi * w[t-1];
    tot_ln_Rec[t] ~ dnorm(E_ln_Rec[t], tau_r);
    res_ln_Rec[t] <- tot_ln_Rec[t] - E_ln_Rec[t];
    w[t] <- phi * w[t-1] + res_ln_Rec[t];

    ## median of total recruits
    tot_Rec[t] <- exp(tot_ln_Rec[t]);
    ## R/S
    ln_RS[t] <- tot_ln_Rec[t] - ln_Sp[t];
    ## brood-yr recruits by age
    for(a in 1:A) {
      Rec[t,a] <- tot_Rec[t] * pi_vec[t,a];
    }
  } ## end t loop over year
  
  ## get predicted calendar year returns by age
  ## matrix Run has dim [(n_yrs-age_min) x A]
  ## step 1: incomplete early broods
  ## first cal yr of this grp is first brood yr + age_min + age_skip
  for(i in 1:(age_max-age_min-age_skip)) {
    ## projected recruits
    for(a in 1:(i+age_skip)) {
      Run[i,a] <- Rec[(age_skip+i)-a+1,a];
    }
    ## imputed recruits
    for(a in (i+1+age_skip):A) {
      lnRec[i,a] ~ dnorm(Rec_mu,Rec_tau);
      Run[i,a] <- exp(lnRec[i,a]);
    }
    ## total run size
    tot_Run[i+age_min+age_skip] <- sum(Run[i,1:A]);
    ## predicted age-prop vec for multinom
    for(a in 1:A) {
      age_v[i,a] <- Run[i,a] / tot_Run[i+age_min];
    }
    ## multinomial for age comp
    dat_age[i,1:A] ~ dmulti(age_v[i,1:A],dat_age[i,A+1]);
    lp_age[i] <- logdensity.multi(dat_age[i,1:A],age_v[i,1:A],dat_age[i,A+1]);
  }
  
  ## step 2: info from complete broods
  ## first cal yr of this grp is first brood yr + age_max
  for(i in (A-age_skip):(n_yrs-age_min-age_skip+n_fore)) {
    for(a in 1:A) {
      Run[i,a] <- Rec[(age_skip+i)-a+1,a];
    }
    ## total run size
    tot_Run[i+age_min+age_skip] <- sum(Run[i,1:A]);
    ## predicted age-prop vec for multinom
    for(a in 1:A) {
      age_v[i,a] <- Run[i,a] / tot_Run[i+age_min];
    }
    ## multinomial for age comp
    dat_age[i,1:A] ~ dmulti(age_v[i,1:A],dat_age[i,A+1]);
    #lp_age[i] <- logdensity.multi(dat_age[i,1:A],age_v[i,1:A],dat_age[i,A+1]);
    lp_age[i] <- ifelse(i < n_yrs-age_min-age_skip+n_fore,
    logdensity.multi(dat_age[i,1:A],age_v[i,1:A],dat_age[i,A+1]),0)
  }
  
  ## get predicted calendar year spawners
  ## first cal yr is first brood yr
  for(t in 1:(n_yrs+n_fore)) {
    ## obs model for spawners
    # Sp[t] <- max(10,tot_Run[t] - dat_harv[t]);
    est_harv[t] = h_rate[t] * tot_Run[t];
    dat_harv[t] ~ dlnorm(log(est_harv[t]), 20);
    Sp[t] = tot_Run[t] - est_harv[t];
    ln_Sp[t] <- log(Sp[t]);
    ln_dat_esc[t] ~ dnorm(ln_Sp[t], tau_s);
    lp_esc[t] <- ifelse(t < n_yrs + 1,logdensity.norm(ln_dat_esc[t],ln_Sp[t], tau_s),0);
  }
  
} ## end model description
    
  ", file=file.path(jagsdir, "IPM_BH_cov_AR_resid.txt"))

```


***

# Fitting the models and generating the one year ahead forecasts

Before fitting the model in JAGS, we need to specify the MCMC control parameters.

```{r jags_IO_base}
## empty list for fits
n_mods <- 3
mod_fits <- vector("list", n_mods)
```

```{r jags_setup}
## 1. Data to pass to JAGS
dat_jags <- list(dat_age = dat_age,
                 ln_dat_esc = ln_dat_esc,
                 dat_harv = dat_harv,
                 A = A,
                 age_min = age_min,
                 age_max = age_max,
                 age_skip = age_skip,
                 n_yrs = n_yrs,
                 n_fore = n_fore)

## 2. MCMC control params
mcmc_ctrl <- list(
  chains = 4,
  length = 20000,#5e5,
  burn = 10000,#2e5,
  thin = 4#400
)
## total number of MCMC samples after burnin
mcmc_samp <- mcmc_ctrl$length*mcmc_ctrl$chains/mcmc_ctrl$thin
```

```{r start_timer, include = FALSE}
## start timer
timer_start <- proc.time() 
```

## Model with all covariates

Please note that the following code takes ~20 min to run on a quad-core machine with 3.5 GHz Intel processors.

```{r inits_cov}

## set of multi-covariate models
cset <- colnames(scl_cvrs)
dat_jags$n_cov <- length(cset)
dat_jags$mod_cvrs <- scl_cvrs[, cset]
```

First, we will fit a beverton holt model assuming MA1 and AR1 recruitment residuals

```{r fit_BH_cov_MA1_AR1_show, eval = FALSE, message = FALSE, warning = FALSE, cache = FALSE}
## function for inits
init_vals_cov <- function() {
  list(alpha = 5,
       beta_inv = exp(mean(ln_dat_esc, na.rm = TRUE)),
       gamma = rep(0, 3),
       pi_tau = 10,
       pi_eta = rep(1,A),
       pi_vec = matrix(c(0.01,0.35,0.47,0.15,0.01,0.01),
                       n_yrs-age_min+n_fore, A, 
                       byrow = TRUE),
       Rec_mu = log(1000),
       Rec_sig = 0.1,
       #tot_ln_Rec = rep(log(1000), n_yrs - age_min + n_fore),
       phi_prior = 0.75,theta_res_prior = 0.75,
       innov_1 = 0)
}

## params/states to return
par_jags <- c("alpha","E_BH_a","ln_BH_a",
              "beta",
              "gamma",
              "Sp","Rec","tot_ln_Rec","ln_RS",
              "pi_eta","pi_tau",
              "sigma_r","sigma_s","res_ln_Rec","w","theta_res","phi",
              "lp_age","lp_esc"
              )

cat("Count =", 1, "; Time =", round(((proc.time()-timer_start)/60)["elapsed"], 1), "\n",
          file="cnt_time.txt", append=TRUE)

## fit model & save it
# mod_fits[[1]] <- fit_jags("IPM_BH_cov_MA1_AR1.txt", dat_jags, par_jags,
#                           init_vals_cov, mcmc_ctrl)
mod_fits[[1]] <- fit_jags2(model="IPM_BH_cov_MA1_AR1.txt",
                           data=dat_jags,
                           params=par_jags,
                           inits=init_vals_cov,
                           ctrl=mcmc_ctrl
                           )
```

```{r fit_BH_cov_MA1_AR1, echo = FALSE, message = FALSE, warning = FALSE, cache = FALSE, eval=TRUE}

init_vals_cov <- function() {
  list(alpha = 5,
       beta_inv = exp(mean(ln_dat_esc, na.rm = TRUE)),
       gamma = rep(0, 3),
       pi_tau = 10,
       pi_eta = rep(1,A),
       pi_vec = matrix(c(0.01,0.35,0.47,0.15,0.01,0.01),
                       n_yrs-age_min+n_fore, A, 
                       byrow = TRUE),
       Rec_mu = log(1000),
       Rec_sig = 0.1,
       #tot_ln_Rec = rep(log(1000), n_yrs - age_min + n_fore),
       phi_prior = 0.75, theta_res_prior = 0.75,
       innov_1 = 0)
}

## params/states to return
par_jags <- c("alpha","E_BH_a","ln_BH_a",
              "beta",
              "gamma",
              "Sp","Rec","tot_ln_Rec","ln_RS",
              "pi_eta","pi_tau",
              "sigma_r","sigma_s","res_ln_Rec","w","theta_res","phi",
              "lp_age","lp_esc"
              )

cat("Count =", 1, "; Time =", round(((proc.time()-timer_start)/60)["elapsed"], 1), "\n",
          file="cnt_time.txt", append=TRUE)

## if file exists, load it
if(file.exists(file.path(savedir, "fit_bh_cov_MA1_AR1.rds"))) {
  mod_fits[[1]] <- readRDS(file.path(savedir, "fit_bh_cov_MA1_AR1.rds"))
} else { ## else, fit & save
  # mod_fits[[1]] <- fit_jags("IPM_BH_cov_MA1_AR1.txt", dat_jags, par_jags,
  #                           init_vals_cov, mcmc_ctrl)
  mod_fits[[1]] <- fit_jags2(model="IPM_BH_cov_MA1_AR1.txt",
                           data=dat_jags,
                           params=par_jags,
                           inits=init_vals_cov,
                           ctrl=mcmc_ctrl
                           )
  saveRDS(mod_fits[[1]], file.path(savedir, "fit_bh_cov_MA1_AR1.rds"))
}
```

### Model diagnostics

Here is a table of the Gelman & Rubin statistics $(R_{hat})$ for the estimated parameters. Recall that we set an upper threshold of `r Rhat_thresh`, so values larger than that deserve some additional inspection.

```{r diag_BH_MA1_AR1, eval=TRUE}
## params of interest
par_conv <- c("alpha","beta",paste0("gamma[",seq(3),"]"),
              "sigma_r","sigma_s","pi_tau","theta_res",paste0("pi_eta[",seq(A-1),"]"))
## Gelman-Rubin
gelman.diag(mod_fits[[1]][,par_conv])
## Autocorrelation
# t(round(autocorr.diag(mod_fits[[1]][,par_conv],
#                       lags = seq(mcmc_ctrl$thin, 4*mcmc_ctrl$thin, mcmc_ctrl$thin),
#                       relative=FALSE), 2))
## Use ShinyStan to look at effective draws, Gelman-Rubin, Autocorrelation
fit_bh_cov_MA1_AR1 <- readRDS(file.path(savedir,"fit_bh_cov_MA1_AR1.rds"))
my_sso2 <- launch_shinystan(as.shinystan(fit_bh_cov_MA1_AR1))
summary_stats2<-data.frame(lapply(c("rhat","neff","mean","sd","quantiles"),function(x) retrieve(my_sso2,what=x)))
colnames(summary_stats2)[1:4]<-c("rhat","neff","mean","sd")
write.csv(summary_stats2,file.path(savedir,"Summary_stats_AR1_MA1.csv"))
```



next we will fit a beverton holt model assuming AR1 process errors only

```{r fit_BH_cov_AR1_show, eval=FALSE, message=FALSE, warning=FALSE, cache=FALSE}
## function for inits
init_vals_cov <- function() {
  list(alpha = 5,
       beta_inv = exp(mean(ln_dat_esc, na.rm = TRUE)),
       gamma = rep(0, 3),
       pi_tau = 10,
       pi_eta = rep(1,A),
       pi_vec = matrix(c(0.01,0.35,0.47,0.15,0.01,0.01),
                       n_yrs-age_min+n_fore, A, 
                       byrow = TRUE),
       Rec_mu = log(1000),
       Rec_sig = 0.1,
       tot_ln_Rec = rep(log(1000), n_yrs - age_min + n_fore),
       phi_prior = 0.5,
       innov_1 = 0)
}

## params/states to return
par_jags <- c("alpha","E_BH_a","ln_BH_a",
              "beta",
              "gamma",
              "Sp","Rec","tot_ln_Rec","ln_RS",
              "pi_eta","pi_tau",
              "sigma_r","sigma_s","res_ln_Rec",
              "lp_age","lp_esc","phi"
              )

cat("Count =", 2, "; Time =", round(((proc.time()-timer_start)/60)["elapsed"], 1), "\n",
          file="cnt_time.txt", append=TRUE)

## fit model & save it
# mod_fits[[2]] <- fit_jags("IPM_BH_cov_AR.txt", dat_jags, par_jags,
#                           init_vals_cov, mcmc_ctrl)
mod_fits[[2]] <- fit_jags2(model="IPM_BH_cov_AR.txt",
                           data=dat_jags,
                           params=par_jags,
                           inits=init_vals_cov,
                           ctrl=mcmc_ctrl
                           )
```


```{r fit_BH_cov_AR1, echo = FALSE, message = FALSE, warning = FALSE, cache = FALSE, eval=TRUE}

init_vals_cov <- function() {
  list(alpha = 5,
       beta_inv = exp(mean(ln_dat_esc, na.rm = TRUE)),
       gamma = rep(0, 3),
       pi_tau = 10,
       pi_eta = rep(1,A),
       pi_vec = matrix(c(0.01,0.35,0.47,0.15,0.01,0.01),
                       n_yrs-age_min+n_fore, A, 
                       byrow = TRUE),
       Rec_mu = log(1000),
       Rec_sig = 0.1,
       tot_ln_Rec = rep(log(1000), n_yrs - age_min + n_fore),
       phi_prior = 0.5,
       innov_1 = 0)
}

## params/states to return
par_jags <- c("alpha","E_BH_a","ln_BH_a",
              "beta",
              "gamma",
              "Sp","Rec","tot_ln_Rec","ln_RS",
              "pi_eta","pi_tau",
              "sigma_r","sigma_s","res_ln_Rec",
              "lp_age","lp_esc","phi"
              )

cat("Count =", 2, "; Time =", round(((proc.time()-timer_start)/60)["elapsed"], 1), "\n",
          file="cnt_time.txt", append=TRUE)

## if file exists, load it
if(file.exists(file.path(savedir, "fit_bh_cov_AR.rds"))) {
  mod_fits[[2]] <- readRDS(file.path(savedir, "fit_bh_cov_AR.rds"))
} else { ## else, fit & save
  # mod_fits[[2]] <- fit_jags("IPM_BH_cov_AR.txt", dat_jags, par_jags,
  #                           init_vals_cov, mcmc_ctrl)
  mod_fits[[2]] <- fit_jags2(model="IPM_BH_cov_AR.txt",
                           data=dat_jags,
                           params=par_jags,
                           inits=init_vals_cov,
                           ctrl=mcmc_ctrl
                           )
  saveRDS(mod_fits[[2]], file.path(savedir, "fit_bh_cov_AR.rds"))
}
```


### Model diagnostics

Here is a table of the Gelman & Rubin statistics $(R_{hat})$ for the estimated parameters. Recall that we set an upper threshold of `r Rhat_thresh`, so values larger than that deserve some additional inspection.

```{r diag_BH_AR1, eval=TRUE}
## params of interest
par_conv <- c("alpha","beta",paste0("gamma[",seq(3),"]"),
              "sigma_r","sigma_s","pi_tau","phi",paste0("pi_eta[",seq(A-1),"]"))
## Gelman-Rubin
gelman.diag(mod_fits[[2]][,par_conv])
## Autocorrelation
# t(round(autocorr.diag(mod_fits[[2]][,par_conv],
#                       lags = seq(mcmc_ctrl$thin, 4*mcmc_ctrl$thin, mcmc_ctrl$thin),
#                       relative=FALSE), 2))
## Use ShinyStan to look at effective draws, Gelman-Rubin, Autocorrelation
fit_bh_cov_AR <- readRDS(file.path(savedir,"fit_bh_cov_AR.rds"))
my_sso <- launch_shinystan(as.shinystan(fit_bh_cov_AR))
summary_stats1<-data.frame(lapply(c("rhat","neff","mean","sd","quantiles"),function(x) retrieve(my_sso,what=x)))
colnames(summary_stats1)[1:4]<-c("rhat","neff","mean","sd")
write.csv(summary_stats1,file.path(savedir,"Summary_stats_AR.csv"))
```


next we will fit a beverton holt model assuming AR1 recruitment residuals only

```{r fit_BH_cov_AR1_resid_show, eval=FALSE, message=FALSE, warning=FALSE, cache=FALSE}
## function for inits
init_vals_cov <- function() {
  list(alpha = 5,
       beta_inv = exp(mean(ln_dat_esc, na.rm = TRUE)),
       gamma = rep(0, 3),
       pi_tau = 10,
       pi_eta = rep(1,A),
       pi_vec = matrix(c(0.01,0.35,0.47,0.15,0.01,0.01),
                       n_yrs-age_min+n_fore, A, 
                       byrow = TRUE),
       Rec_mu = log(1000),
       Rec_sig = 0.1,
       tot_ln_Rec = rep(log(1000), n_yrs - age_min + n_fore),
       phi_prior = 0.5,
       innov_1 = 0)
}

## params/states to return
par_jags <- c("alpha","E_BH_a","ln_BH_a",
              "beta",
              "gamma",
              "Sp","Rec","tot_ln_Rec","ln_RS",
              "pi_eta","pi_tau",
              "sigma_r","sigma_s","res_ln_Rec",
              "lp_age","lp_esc","phi"
              )

cat("Count =", 3, "; Time =", round(((proc.time()-timer_start)/60)["elapsed"], 1), "\n",
          file="cnt_time.txt", append=TRUE)

## fit model & save it
# mod_fits[[3]] <- fit_jags("IPM_BH_cov_AR_resid.txt", dat_jags, par_jags,
#                           init_vals_cov, mcmc_ctrl)
mod_fits[[3]] <- fit_jags2(model="IPM_BH_cov_AR_resid.txt",
                           data=dat_jags,
                           params=par_jags,
                           inits=init_vals_cov,
                           ctrl=mcmc_ctrl
                           )
```


```{r fit_BH_cov_AR1_resid, echo = FALSE, message = FALSE, warning = FALSE, cache = FALSE, eval=TRUE}

init_vals_cov <- function() {
  list(alpha = 5,
       beta_inv = exp(mean(ln_dat_esc, na.rm = TRUE)),
       gamma = rep(0, 3),
       pi_tau = 10,
       pi_eta = rep(1,A),
       pi_vec = matrix(c(0.01,0.35,0.47,0.15,0.01,0.01),
                       n_yrs-age_min+n_fore, A, 
                       byrow = TRUE),
       Rec_mu = log(1000),
       Rec_sig = 0.1,
       tot_ln_Rec = rep(log(1000), n_yrs - age_min + n_fore),
       phi_prior = 0.5,
       innov_1 = 0)
}

## params/states to return
par_jags <- c("alpha","E_BH_a","ln_BH_a",
              "beta",
              "gamma",
              "Sp","Rec","tot_ln_Rec","ln_RS",
              "pi_eta","pi_tau",
              "sigma_r","sigma_s","res_ln_Rec",
              "lp_age","lp_esc","phi"
              )

cat("Count =", 3, "; Time =", round(((proc.time()-timer_start)/60)["elapsed"], 1), "\n",
          file="cnt_time.txt", append=TRUE)

## if file exists, load it
if(file.exists(file.path(savedir, "fit_bh_cov_AR_resid.rds"))) {
  mod_fits[[3]] <- readRDS(file.path(savedir, "fit_bh_cov_AR_resid.rds"))
} else { ## else, fit & save
  # mod_fits[[3]] <- fit_jags("IPM_BH_cov_AR_resid.txt", dat_jags, par_jags,
  #                           init_vals_cov, mcmc_ctrl)
  mod_fits[[3]] <- fit_jags2(model="IPM_BH_cov_AR_resid.txt",
                           data=dat_jags,
                           params=par_jags,
                           inits=init_vals_cov,
                           ctrl=mcmc_ctrl
                           )
  saveRDS(mod_fits[[3]], file.path(savedir, "fit_bh_cov_AR_resid.rds"))
}
```


### Model diagnostics AR1 recruitment residuals

Here is a table of the Gelman & Rubin statistics $(R_{hat})$ for the estimated parameters. Recall that we set an upper threshold of `r Rhat_thresh`, so values larger than that deserve some additional inspection.

```{r diag_BH_AR1_resid, eval=TRUE}
## params of interest
par_conv <- c("alpha","beta",paste0("gamma[",seq(3),"]"),
              "sigma_r","sigma_s","pi_tau","phi",paste0("pi_eta[",seq(A-1),"]"))
## Gelman-Rubin
gelman.diag(mod_fits[[3]][,par_conv])
## Autocorrelation
# t(round(autocorr.diag(mod_fits[[3]][,par_conv],
#                       lags = seq(mcmc_ctrl$thin, 4*mcmc_ctrl$thin, mcmc_ctrl$thin),
#                       relative=FALSE), 2))
## Use ShinyStan to look at effective draws, Gelman-Rubin, Autocorrelation
fit_bh_cov_AR_resid <- readRDS(file.path(savedir,"fit_bh_cov_AR_resid.rds"))
my_sso <- launch_shinystan(as.shinystan(fit_bh_cov_AR_resid))
summary_stats3<-data.frame(lapply(c("rhat","neff","mean","sd","quantiles"),function(x) retrieve(my_sso,what=x)))
colnames(summary_stats3)[1:4]<-c("rhat","neff","mean","sd")
write.csv(summary_stats3,file.path(savedir,"Summary_stats_AR_resid.csv"))
```

# Model selection

Via `loo()` and `compare()` with full table of results. Note that `elpd_diff` will be negative (positive) if the expected predictive accuracy for the first (second) model is higher.

```{r get_LOOIC_c, warning=FALSE, cache=FALSE}
LOOIC <- vector("list", n_mods)
## extract log densities from JAGS objects
for(i in 1:n_mods) {
  ## convert mcmc.list to matrix
  tmp_lp <- as.matrix(mod_fits[[i]])
  ## extract pointwise likelihoods
  tmp_lp <- tmp_lp[,grepl("lp_", colnames(tmp_lp))]
  ## could choose to evaluate fit only to escapement instead of age (default commented out)
  ##tmp_lp<-tmp_lp[,grepl("esc", colnames(tmp_lp))]
  ## if numerical underflows, convert -Inf to 5% less than min(likelihood)
  if(any(is.infinite(tmp_lp))) {
    tmp_lp[is.infinite(tmp_lp)] <- NA
    tmp_min <- min(tmp_lp, na.rm = TRUE)
    tmp_lp[is.na(tmp_lp)] <- tmp_min * 1.05
  }
  ## calculate LOOIC
  LOOIC[[i]] <- loo(tmp_lp)
}


## compute pseudo weights
model_weights <- loo_model_weights(LOOIC, method = "pseudobma",optim_method = "BFGS", optim_control = list(), BB = TRUE)

## LOOIC for all data
tbl_LOOIC <- round(loo_compare(x = LOOIC), 2)
rownames(tbl_LOOIC) <- sub("model", "", rownames(tbl_LOOIC))
tbl_LOOIC <- tbl_LOOIC[order(as.numeric(rownames(tbl_LOOIC))), ]
tbl_LOOIC <- cbind(model = c("B-H","B-H","B-H"),
                   error = c("MA1_AR1","AR1","AR1_resid"),
                   as.data.frame(tbl_LOOIC),pseudo_bma_weight = as.matrix(model_weights))
tbl_LOOIC[order(tbl_LOOIC[,"looic"]), ]


## best model
best_i <- which(tbl_LOOIC[,"looic"] == min(tbl_LOOIC[,"looic"]))
best_fit <- mod_fits[[best_i]]
```

These results show that the `r mod_names[best_i,"mod"]` model with `r mod_names[best_i,"error"]` error has the lowest LOOIC value.  All results will be derived from model averaging based on pseudo bayesian model average weights. 


# Model Selection Via Approximate leave-future-out cross validation
THIS SECTION NEEDS TO BE BETTER INTEGRATED INTO THE REST OF THE CODE:
1) need to put it into the version that generates re-fits, or possibly into a separate APP
2) need to better set up work directories for where original "full" fits vs "re-fits" with subset of data go so that the code below can find them without creating folders and moving things
3) need to work on nameing conventions for re-fit files and how re-fit function below loads them...i suggest that file name is indexed by year of data instead of year of refitting!!!!


```{r }

#load complete model fits & model refits with subset data
loadmodfits<-function(modelnames){
  mod_fits<-list()
  for(i in 1:length(modelnames)){
    mod_fits[[i]] <- readRDS(file.path(savedir,paste0("fit_",modelnames[i],".rds")))
  }
  return(mod_fits)
}

#refits
loadrefits<-function(refitname,N,L){
  numrefits<-N-L+1
  re_fits<-list()
  for(i in 1:numrefits){
     re_fits[[i]] <- readRDS(file.path(savedir,paste0("IPM_",refitname,"_y",i,".rds")))
  }
  return(re_fits)
}

# functions modified from:
# https://github.com/paul-buerkner/LFO-CV-paper/blob/master/case-study-LFO-CV.Rmd

# more stable than log(sum(exp(x))) 
log_sum_exp <- function(x) {
  max_x <- max(x)
  max_x + log(sum(exp(x - max_x)))
}

# more stable than log(mean(exp(x)))
log_mean_exp <- function(x) {
  log_sum_exp(x) - log(length(x))
}

# compute log of raw importance ratios
# sums over observations *not* over posterior samples
sum_log_ratios <- function(ll, ids = NULL) {
  if (!is.null(ids)) ll <- ll[, ids, drop = FALSE]
  - rowSums(ll)
}
# for printing comparisons later
rbind_print <- function(...) {
  round(rbind(...), digits = 2)
}

#function to extract log likelihood from fitted model
extract_log_lik<-function(m,esc_only,N,mod_fits){
  #extract pontwise log likelihoods
  tmp_lp <- as.matrix(mod_fits[[m]])
  ## extract pointwise likelihoods
  tmp_lp <- tmp_lp[,grepl("lp_", colnames(tmp_lp))]
  ## if numerical underflows, convert -Inf to 5% less than min(likelihood)
  if(any(is.infinite(tmp_lp))) {
    tmp_lp[is.infinite(tmp_lp)] <- NA
    tmp_min <- min(tmp_lp, na.rm = TRUE)
    tmp_lp[is.na(tmp_lp)] <- tmp_min * 1.05
  }
  if(esc_only =="Yes"){
    tmp_lp<-tmp_lp[,grepl("esc", colnames(tmp_lp))]
  }
  #get yrs assoc
  names_loglik<-data.frame(strsplit(colnames(tmp_lp),"\\[|\\]"))
  yrnames<-as.numeric(names_loglik[2,])
  
  loglik <- matrix(NA,ncol=N,nrow=dim(tmp_lp)[1])
  for(i in 1:N){
    if(!is.null(ncol(tmp_lp[,yrnames==i]))){
      loglik[,i] = apply(tmp_lp[,yrnames==i],1,sum)
    }else(loglik[,i] = tmp_lp[,yrnames==i])
  }
  return(loglik)
}


approx_LFO<-function(N=N,L,m=m,esc_only,mod_fits,userefits,refitname,thres){
  loglik =  extract_log_lik(m=m, esc_only = esc_only,N=N,mod_fits = mod_fits)
  ## look at Pareto k's
  k_LOOIC<-pareto_k_values(loo(loglik))[(L+1):N]
  if(userefits=="Yes"){
    re_fits =loadrefits(refitname=refitname,N=N,L=L)
  }
  i_refit <- L
  refits <- L
  ks <- NULL
  approx_elpds_1sap <- rep(NA, N)
  for (i in (N - 1):L) {
    logratio <- sum_log_ratios(loglik, (i + 1):N)
    psis_obj <- suppressWarnings(psis(logratio))
    k<-pareto_k_values(psis_obj)
    ks <- c(ks, k)
    if(k>thres & userefits=="Yes"){
    #use_refit of model based on the first[i] observations
      i_refit <- i
      refits <- c(refits, i)
      loglik =  extract_log_lik(m=m, esc_only = esc_only,N=N,mod_fits = re_fits[[(i+1)-L+1]])
      approx_elpds_1sap[i + 1] <- log_mean_exp(loglik[, i + 1])
    }else{
      lw <- weights(psis_obj, normalize = TRUE)[, 1]
      approx_elpds_1sap[i + 1] <- log_sum_exp(lw + loglik[, i + 1])
    }
  }
  results<-list(approx_elpds_1sap,ks,k_LOOIC)
  names(results)<-c("LFO","ks","k_LOOIC")
  return(results)
}

plot_ks <- function(ks, thres = 0.7,N,L) {
  ids = N:(L + 1)
  dat_ks <- data.frame(ks = ks, ids = ids)
  ggplot(dat_ks, aes(x = ids, y = ks)) + 
    geom_point(aes(color = ks > thres), shape = 3, show.legend = FALSE) + 
    geom_hline(yintercept = thres, linetype = 2, color = "red2") + 
    scale_color_manual(values = c("cornflowerblue", "darkblue")) + 
    labs(x = "Data point", y = "Pareto k") + 
    ylim(-0.5, max(dat_ks$ks))
}

L=20
N=yr_last-(yr_frst-1)
esc_only="Yes"
mod_fits<-loadmodfits(modelnames=c("bh_cov_MA1_AR1","bh_cov_AR","bh_cov_AR_resid"))


LFO1<-approx_LFO(N=N,L=L,m=1,esc_only=esc_only,mod_fits=mod_fits,userefits="No",refitname="BH_cov_MA1_AR1",thres=0.7)
plot_ks(LFO1$ks,N=N,L=L)
plot_ks(LFO1$k_LOOIC,N=N,L=L)

LFO2<-approx_LFO(N=N,L=L,m=2,esc_only=esc_only,mod_fits=mod_fits,userefits="No",refitname="BH_cov_AR",thres=0.7)
plot_ks(LFO2$ks, N=N,L=L)
plot_ks(LFO2$k_LOOIC, N=N,L=L)

LFO3<-approx_LFO(N=N,L=L,m=3,esc_only=esc_only,mod_fits=mod_fits,userefits="No",refitname="BH_cov_AR_resid",thres=0.7)
plot_ks(LFO3$ks, N=N,L=L)
plot_ks(LFO3$k_LOOIC, N=N,L=L)

ELPD<-c(sum(LFO1$LFO,na.rm=T),sum(LFO2$LFO,na.rm=T),sum(LFO3$LFO,na.rm=T))
LFOIC<--2*ELPD-min(ELPD)
delta_LFOIC<-LFOIC-min(LFOIC)
names(delta_LFOIC)<-c("MA1_AR1","AR1","AR1_resid")
print(delta_LFOIC)#like loo
w<-exp(ELPD)/sum(exp(ELPD))
names(w)<-c("MA1_AR1","AR1","AR1_resid")
print(w)
barplot(delta_LFOIC,ylab="Delta LFOIC")
```

<!-- ```{r stop_timer, include = FALSE} -->
<!-- ## stop timer -->
<!-- run_time_in_min <- round(((proc.time()-timer_start)/60)["elapsed"], 1) -->
<!-- cat(run_time_in_min, file = "run_time_in_min.txt") -->
<!-- ``` -->


